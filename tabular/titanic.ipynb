{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4ee502bb-70ed-485a-ad77-e32088835efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "67770c2c-deec-4d16-873b-8f16eecc4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/titanic_train.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca380e2d-a103-4095-a3bf-8fb1ae5649c1",
   "metadata": {},
   "source": [
    "### Variable descriptions\n",
    "- **pclass**: A proxy for socio-economic status (SES, i.e. upper, middle, lower): 1st/2nd/3rd\n",
    "- **age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "- **SibSp** (sibling/spouse)\n",
    "- **Parch** (parent/child) The dataset defines family relations in this way\n",
    "- **Cabin** has nan values, but 148 unique values like C85, C123 etc.\n",
    "- **Ticket** has 681 unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2c18c-adb4-425e-a65a-5bab427c7bea",
   "metadata": {},
   "source": [
    "### Peeking into the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae1ec7-1d06-4593-bc5c-acaa4049ddad",
   "metadata": {},
   "source": [
    "What is happening in columns like Ticket, Cabin etc.?\n",
    "\n",
    "Ticket seems to have mostly unique values, but cabins have repeating values -- can convert this into a `cabin_types` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cfc9487b-1e38-4f7f-ae94-8cc4aa1c3bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'C85' 'C123' 'E46' 'G6' 'C103' 'D56' 'A6' 'C23 C25 C27' 'B78' 'D33'\n",
      " 'B30' 'C52' 'B28' 'C83' 'F33' 'F G73' 'E31' 'A5' 'D10 D12' 'D26' 'C110'\n",
      " 'B58 B60' 'E101' 'F E69' 'D47' 'B86' 'F2' 'C2' 'E33' 'B19' 'A7' 'C49'\n",
      " 'F4' 'A32' 'B4' 'B80' 'A31' 'D36' 'D15' 'C93' 'C78' 'D35' 'C87' 'B77'\n",
      " 'E67' 'B94' 'C125' 'C99' 'C118' 'D7' 'A19' 'B49' 'D' 'C22 C26' 'C106'\n",
      " 'C65' 'E36' 'C54' 'B57 B59 B63 B66' 'C7' 'E34' 'C32' 'B18' 'C124' 'C91'\n",
      " 'E40' 'T' 'C128' 'D37' 'B35' 'E50' 'C82' 'B96 B98' 'E10' 'E44' 'A34'\n",
      " 'C104' 'C111' 'C92' 'E38' 'D21' 'E12' 'E63' 'A14' 'B37' 'C30' 'D20' 'B79'\n",
      " 'E25' 'D46' 'B73' 'C95' 'B38' 'B39' 'B22' 'C86' 'C70' 'A16' 'C101' 'C68'\n",
      " 'A10' 'E68' 'B41' 'A20' 'D19' 'D50' 'D9' 'A23' 'B50' 'A26' 'D48' 'E58'\n",
      " 'C126' 'B71' 'B51 B53 B55' 'D49' 'B5' 'B20' 'F G63' 'C62 C64' 'E24' 'C90'\n",
      " 'C45' 'E8' 'B101' 'D45' 'C46' 'D30' 'E121' 'D11' 'E77' 'F38' 'B3' 'D6'\n",
      " 'B82 B84' 'D17' 'A36' 'B102' 'B69' 'E49' 'C47' 'D28' 'E17' 'A24' 'C50'\n",
      " 'B42' 'C148']\n",
      "High level types: {'G', 'E', 'D', 'C', 'B', None, 'F', 'A', 'T'}\n"
     ]
    }
   ],
   "source": [
    "print(df['Cabin'].unique())\n",
    "print('High level types:', set([c[0] if type(c) == str else None for c in df['Cabin']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "46aea089-032f-44ff-a813-d6aa65d051e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age column has 177 / 891 missing values -- going to replace with average age 29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "mean_age = df['Age'].mean()\n",
    "print(f\"Age column has {df['Age'].isna().sum()} / {df.shape[0]} missing values -- going to replace with average age {mean_age}\")\n",
    "\n",
    "# replace with average\n",
    "\n",
    "missing = df['Age'].isna()\n",
    "df.loc[missing, 'Age'] = mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ea584a1f-ff7e-4c63-b9ab-e051dc2f8d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- cabin_types frequencies ---\n",
      "cabin_types\n",
      "C    59\n",
      "B    47\n",
      "D    33\n",
      "E    32\n",
      "A    15\n",
      "F    13\n",
      "G     4\n",
      "T     1\n",
      "Name: count, dtype: int64\n",
      "None rows: 687\n"
     ]
    }
   ],
   "source": [
    "# pull out unique cabin types\n",
    "def map_cabin_type(cabin_val):\n",
    "    if pd.isna(cabin_val):\n",
    "        return None\n",
    "    else:\n",
    "        # first char\n",
    "        return cabin_val[0]\n",
    "\n",
    "# convert cabin to cabin types\n",
    "df['cabin_types'] = df['Cabin'].apply(map_cabin_type)\n",
    "\n",
    "print('--- cabin_types frequencies ---')\n",
    "print(df['cabin_types'].value_counts())\n",
    "print('None rows:', df['cabin_types'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf7c8c-8ea9-4864-8776-2ef5d0b0758f",
   "metadata": {},
   "source": [
    "### Preprocess data to construct training matrices\n",
    "\n",
    "What is not mentioned has been dropped\n",
    "- `Survived`: keep as is (target variable)\n",
    "- `SibSp`: z-normalize\n",
    "- `Parch`: z-normalize\n",
    "- `Fare`: z-normalize\n",
    "- `Age`: would have liked to z-normalize, but 177/\n",
    "- `Sex`: one-hot\n",
    "- `cabin_types`: one-hot\n",
    "- `Embarked`: one-hot\n",
    "- `Pclass`: one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "720849ad-cc8c-4ba1-9156-c7002ca63e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (891, 26)\n",
      "y.shape: (891,)\n"
     ]
    }
   ],
   "source": [
    "# these columns need to be z-normalized\n",
    "to_scale = ['SibSp', 'Parch', 'Fare', 'Age']\n",
    "scaler = StandardScaler()\n",
    "scaled_cols = scaler.fit_transform(df[to_scale])\n",
    "# print(scaled_cols.shape)\n",
    "\n",
    "# these columns are categorical, need to be one-hot encoded\n",
    "onehot = ['cabin_types', 'Embarked', 'Pclass', 'Sex', 'Pclass']\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "onehot_cols = onehot_encoder.fit_transform(df[onehot]).todense()\n",
    "n_onehot_cols = sum([len(cats) for cats in onehot_encoder.categories_])\n",
    "# print(n_onehot_cols, onehot_cols.shape)\n",
    "\n",
    "# construct X and y matrices for the NN\n",
    "examples = df.shape[0]\n",
    "n_cols = n_onehot_cols + len(as_is) + len(to_scale)\n",
    "X = np.zeros((examples, n_cols))\n",
    "\n",
    "i = 0\n",
    "X[: , i:i+len(to_scale)] = scaled_cols\n",
    "i += len(to_scale)\n",
    "X[: , i:i+n_onehot_cols] = onehot_cols\n",
    "print('X.shape:', X.shape)\n",
    "\n",
    "y_true = np.array(df['Survived'])\n",
    "print('y.shape:', y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4539f50a-684a-4e70-aa17-e5bb48aeb7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 712\n",
      "validation size: 179\n"
     ]
    }
   ],
   "source": [
    "# split into train and validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_true, test_size=0.2, random_state=417)\n",
    "\n",
    "print('train size:', X_train.shape[0])\n",
    "print('validation size:', X_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f2597-08ef-4bc8-a17b-87857374b217",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c81c14d0-e515-48ee-80d8-bd386da61ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "fde741ad-4c18-41c6-9df6-839d5ae6499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1]\n",
    "\n",
    "# two-layer MLP\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(input_shape, activation='relu'),\n",
    "    layers.Dense(input_shape, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # prob. of survival\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "40d25d5f-ba19-49eb-aaa0-4efc68623239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 20:18:04.363720: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.6461 - val_loss: 0.5980 - val_accuracy: 0.7207\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 927us/step - loss: 0.5852 - accuracy: 0.7079 - val_loss: 0.5329 - val_accuracy: 0.7654\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 786us/step - loss: 0.5374 - accuracy: 0.7584 - val_loss: 0.4833 - val_accuracy: 0.8101\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 810us/step - loss: 0.5021 - accuracy: 0.7697 - val_loss: 0.4480 - val_accuracy: 0.8045\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 844us/step - loss: 0.4767 - accuracy: 0.7879 - val_loss: 0.4180 - val_accuracy: 0.8436\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 818us/step - loss: 0.4588 - accuracy: 0.7992 - val_loss: 0.3996 - val_accuracy: 0.8883\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 866us/step - loss: 0.4468 - accuracy: 0.8034 - val_loss: 0.3855 - val_accuracy: 0.8715\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 801us/step - loss: 0.4395 - accuracy: 0.8020 - val_loss: 0.3756 - val_accuracy: 0.8994\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 810us/step - loss: 0.4336 - accuracy: 0.8076 - val_loss: 0.3683 - val_accuracy: 0.8883\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 769us/step - loss: 0.4267 - accuracy: 0.8104 - val_loss: 0.3634 - val_accuracy: 0.8883\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 767us/step - loss: 0.4237 - accuracy: 0.8104 - val_loss: 0.3588 - val_accuracy: 0.8827\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 780us/step - loss: 0.4194 - accuracy: 0.8160 - val_loss: 0.3547 - val_accuracy: 0.8939\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 789us/step - loss: 0.4152 - accuracy: 0.8146 - val_loss: 0.3514 - val_accuracy: 0.8827\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 795us/step - loss: 0.4137 - accuracy: 0.8118 - val_loss: 0.3460 - val_accuracy: 0.8939\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 794us/step - loss: 0.4099 - accuracy: 0.8230 - val_loss: 0.3445 - val_accuracy: 0.8883\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 839us/step - loss: 0.4087 - accuracy: 0.8188 - val_loss: 0.3426 - val_accuracy: 0.8994\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 818us/step - loss: 0.4055 - accuracy: 0.8287 - val_loss: 0.3454 - val_accuracy: 0.8939\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 813us/step - loss: 0.4041 - accuracy: 0.8258 - val_loss: 0.3414 - val_accuracy: 0.8827\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 807us/step - loss: 0.4022 - accuracy: 0.8272 - val_loss: 0.3384 - val_accuracy: 0.8827\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 793us/step - loss: 0.4013 - accuracy: 0.8329 - val_loss: 0.3365 - val_accuracy: 0.8939\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db6900f-b259-444b-b1df-0e6bab26ffeb",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0ca6e4c0-8313-4d14-9adc-5a9573ed6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7fcd711e-2a6d-4253-b7f0-5e80d04bf42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.894\n",
      "AUC: 0.901\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       115\n",
      "           1       0.87      0.83      0.85        64\n",
      "\n",
      "    accuracy                           0.89       179\n",
      "   macro avg       0.89      0.88      0.88       179\n",
      "weighted avg       0.89      0.89      0.89       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_probs = model.predict(X_val, verbose=False)\n",
    "THRESH = 0.5\n",
    "y_pred = np.array(y_probs > THRESH, dtype=int).squeeze()\n",
    "\n",
    "print('Accuracy:', '{:.3f}'.format(accuracy_score(y_val, y_pred)))\n",
    "print('AUC:', '{:.3f}'.format(roc_auc_score(y_val, y_probs)))\n",
    "print('\\n', classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9476f0e1-4157-408e-9b5d-19424292bce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-book",
   "language": "python",
   "name": "dl-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
