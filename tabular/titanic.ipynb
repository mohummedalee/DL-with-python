{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ee502bb-70ed-485a-ad77-e32088835efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67770c2c-deec-4d16-873b-8f16eecc4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/titanic_train.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca380e2d-a103-4095-a3bf-8fb1ae5649c1",
   "metadata": {},
   "source": [
    "### Variable descriptions\n",
    "- **pclass**: A proxy for socio-economic status (SES, i.e. upper, middle, lower): 1st/2nd/3rd\n",
    "- **age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "- **SibSp** (sibling/spouse)\n",
    "- **Parch** (parent/child) The dataset defines family relations in this way\n",
    "- **Cabin** has nan values, but 148 unique values like C85, C123 etc.\n",
    "- **Ticket** has 681 unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2c18c-adb4-425e-a65a-5bab427c7bea",
   "metadata": {},
   "source": [
    "### Peeking into the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae1ec7-1d06-4593-bc5c-acaa4049ddad",
   "metadata": {},
   "source": [
    "What is happening in columns like Ticket, Cabin etc.?\n",
    "\n",
    "Ticket seems to have mostly unique values, but cabins have repeating values -- can convert this into a `cabin_types` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfc9487b-1e38-4f7f-ae94-8cc4aa1c3bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'C85' 'C123' 'E46' 'G6' 'C103' 'D56' 'A6' 'C23 C25 C27' 'B78' 'D33'\n",
      " 'B30' 'C52' 'B28' 'C83' 'F33' 'F G73' 'E31' 'A5' 'D10 D12' 'D26' 'C110'\n",
      " 'B58 B60' 'E101' 'F E69' 'D47' 'B86' 'F2' 'C2' 'E33' 'B19' 'A7' 'C49'\n",
      " 'F4' 'A32' 'B4' 'B80' 'A31' 'D36' 'D15' 'C93' 'C78' 'D35' 'C87' 'B77'\n",
      " 'E67' 'B94' 'C125' 'C99' 'C118' 'D7' 'A19' 'B49' 'D' 'C22 C26' 'C106'\n",
      " 'C65' 'E36' 'C54' 'B57 B59 B63 B66' 'C7' 'E34' 'C32' 'B18' 'C124' 'C91'\n",
      " 'E40' 'T' 'C128' 'D37' 'B35' 'E50' 'C82' 'B96 B98' 'E10' 'E44' 'A34'\n",
      " 'C104' 'C111' 'C92' 'E38' 'D21' 'E12' 'E63' 'A14' 'B37' 'C30' 'D20' 'B79'\n",
      " 'E25' 'D46' 'B73' 'C95' 'B38' 'B39' 'B22' 'C86' 'C70' 'A16' 'C101' 'C68'\n",
      " 'A10' 'E68' 'B41' 'A20' 'D19' 'D50' 'D9' 'A23' 'B50' 'A26' 'D48' 'E58'\n",
      " 'C126' 'B71' 'B51 B53 B55' 'D49' 'B5' 'B20' 'F G63' 'C62 C64' 'E24' 'C90'\n",
      " 'C45' 'E8' 'B101' 'D45' 'C46' 'D30' 'E121' 'D11' 'E77' 'F38' 'B3' 'D6'\n",
      " 'B82 B84' 'D17' 'A36' 'B102' 'B69' 'E49' 'C47' 'D28' 'E17' 'A24' 'C50'\n",
      " 'B42' 'C148']\n",
      "High level types: {'C', 'E', 'T', 'A', None, 'B', 'D', 'G', 'F'}\n"
     ]
    }
   ],
   "source": [
    "print(df['Cabin'].unique())\n",
    "print('High level types:', set([c[0] if type(c) == str else None for c in df['Cabin']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46aea089-032f-44ff-a813-d6aa65d051e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age column has 177 / 891 missing values -- going to replace with average age 29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "mean_age = df['Age'].mean()\n",
    "print(f\"Age column has {df['Age'].isna().sum()} / {df.shape[0]} missing values -- going to replace with average age {mean_age}\")\n",
    "\n",
    "# replace with average\n",
    "missing = df['Age'].isna()\n",
    "df.loc[missing, 'Age'] = mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea584a1f-ff7e-4c63-b9ab-e051dc2f8d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- cabin_types frequencies ---\n",
      "cabin_types\n",
      "C    59\n",
      "B    47\n",
      "D    33\n",
      "E    32\n",
      "A    15\n",
      "F    13\n",
      "G     4\n",
      "T     1\n",
      "Name: count, dtype: int64\n",
      "None rows: 687\n"
     ]
    }
   ],
   "source": [
    "# pull out unique cabin types\n",
    "def map_cabin_type(cabin_val):\n",
    "    if pd.isna(cabin_val):\n",
    "        return None\n",
    "    else:\n",
    "        # first char\n",
    "        return cabin_val[0]\n",
    "\n",
    "# convert cabin to cabin types\n",
    "df['cabin_types'] = df['Cabin'].apply(map_cabin_type)\n",
    "\n",
    "print('--- cabin_types frequencies ---')\n",
    "print(df['cabin_types'].value_counts())\n",
    "print('None rows:', df['cabin_types'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf7c8c-8ea9-4864-8776-2ef5d0b0758f",
   "metadata": {},
   "source": [
    "### Preprocess data to construct training matrices\n",
    "\n",
    "What is not mentioned has been dropped\n",
    "- `Survived`: keep as is (target variable)\n",
    "- `SibSp`: z-normalize\n",
    "- `Parch`: z-normalize\n",
    "- `Fare`: z-normalize\n",
    "- `Age`: would have liked to z-normalize, but 177/\n",
    "- `Sex`: one-hot\n",
    "- `cabin_types`: one-hot\n",
    "- `Embarked`: one-hot\n",
    "- `Pclass`: one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "720849ad-cc8c-4ba1-9156-c7002ca63e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these columns need to be z-normalized\n",
    "to_scale = ['SibSp', 'Parch', 'Fare', 'Age']\n",
    "scaler = StandardScaler()\n",
    "scaled_cols = scaler.fit(df[to_scale])\n",
    "\n",
    "# these columns are categorical, need to be one-hot encoded\n",
    "onehot = ['cabin_types', 'Embarked', 'Pclass', 'Sex', 'Pclass']\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "onehot_cols = onehot_encoder.fit(df[onehot])\n",
    "\n",
    "def vectorize_data(df, scaler, onehot_encoder):\n",
    "    scaled_cols = scaler.transform(df[to_scale])\n",
    "    \n",
    "    onehot_cols = onehot_encoder.transform(df[onehot]).todense()\n",
    "    n_onehot_cols = sum([len(cats) for cats in onehot_encoder.categories_])\n",
    "\n",
    "    # create empty matrix\n",
    "    examples = df.shape[0]\n",
    "    n_cols = n_onehot_cols + len(to_scale)\n",
    "    X = np.zeros((examples, n_cols))\n",
    "\n",
    "    # fill out column-by-column\n",
    "    i = 0\n",
    "    X[: , i:i+len(to_scale)] = scaled_cols\n",
    "    i += len(to_scale)\n",
    "    X[: , i:i+n_onehot_cols] = onehot_cols\n",
    "    print('X.shape:', X.shape)    \n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0053844-c59e-4c2b-befc-b48552bf05c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (891, 25)\n",
      "y.shape: (891,)\n"
     ]
    }
   ],
   "source": [
    "X = vectorize_data(df, scaler, onehot_encoder)\n",
    "\n",
    "y_true = np.array(df['Survived'])\n",
    "print('y.shape:', y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4539f50a-684a-4e70-aa17-e5bb48aeb7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 712\n",
      "validation size: 179\n"
     ]
    }
   ],
   "source": [
    "# split training data into train and validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_true, test_size=0.2, random_state=417)\n",
    "\n",
    "print('train size:', X_train.shape[0])\n",
    "print('validation size:', X_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f2597-08ef-4bc8-a17b-87857374b217",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c81c14d0-e515-48ee-80d8-bd386da61ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fde741ad-4c18-41c6-9df6-839d5ae6499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1]\n",
    "\n",
    "# two-layer MLP\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(input_shape, activation='relu'),\n",
    "    layers.Dense(input_shape, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # prob. of survival\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40d25d5f-ba19-49eb-aaa0-4efc68623239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 21:35:58.104157: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.7135 - val_loss: 0.5225 - val_accuracy: 0.8436\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 0s 915us/step - loss: 0.5216 - accuracy: 0.7837 - val_loss: 0.4356 - val_accuracy: 0.8827\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 0s 817us/step - loss: 0.4743 - accuracy: 0.7978 - val_loss: 0.3928 - val_accuracy: 0.8827\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 0s 792us/step - loss: 0.4520 - accuracy: 0.8020 - val_loss: 0.3717 - val_accuracy: 0.8827\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 0s 830us/step - loss: 0.4434 - accuracy: 0.8062 - val_loss: 0.3644 - val_accuracy: 0.8827\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 0s 895us/step - loss: 0.4390 - accuracy: 0.8090 - val_loss: 0.3566 - val_accuracy: 0.8883\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 0s 865us/step - loss: 0.4326 - accuracy: 0.8118 - val_loss: 0.3501 - val_accuracy: 0.8939\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 0s 840us/step - loss: 0.4272 - accuracy: 0.8118 - val_loss: 0.3479 - val_accuracy: 0.8883\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 0s 823us/step - loss: 0.4247 - accuracy: 0.8188 - val_loss: 0.3455 - val_accuracy: 0.8883\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 0s 805us/step - loss: 0.4213 - accuracy: 0.8174 - val_loss: 0.3438 - val_accuracy: 0.8994\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 0s 810us/step - loss: 0.4177 - accuracy: 0.8244 - val_loss: 0.3415 - val_accuracy: 0.8939\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 0s 836us/step - loss: 0.4150 - accuracy: 0.8202 - val_loss: 0.3425 - val_accuracy: 0.8771\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 0s 810us/step - loss: 0.4140 - accuracy: 0.8287 - val_loss: 0.3383 - val_accuracy: 0.8939\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 0s 816us/step - loss: 0.4110 - accuracy: 0.8287 - val_loss: 0.3343 - val_accuracy: 0.9050\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 0s 793us/step - loss: 0.4085 - accuracy: 0.8315 - val_loss: 0.3333 - val_accuracy: 0.8994\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 0s 785us/step - loss: 0.4070 - accuracy: 0.8272 - val_loss: 0.3323 - val_accuracy: 0.8994\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 0s 833us/step - loss: 0.4042 - accuracy: 0.8343 - val_loss: 0.3311 - val_accuracy: 0.9050\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 0s 818us/step - loss: 0.4027 - accuracy: 0.8287 - val_loss: 0.3310 - val_accuracy: 0.9050\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 0s 835us/step - loss: 0.4007 - accuracy: 0.8287 - val_loss: 0.3286 - val_accuracy: 0.8994\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 0s 926us/step - loss: 0.4004 - accuracy: 0.8315 - val_loss: 0.3264 - val_accuracy: 0.8994\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db6900f-b259-444b-b1df-0e6bab26ffeb",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fcd711e-2a6d-4253-b7f0-5e80d04bf42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.899\n",
      "AUC: 0.903\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93       115\n",
      "           1       0.96      0.75      0.84        64\n",
      "\n",
      "    accuracy                           0.90       179\n",
      "   macro avg       0.92      0.87      0.88       179\n",
      "weighted avg       0.91      0.90      0.90       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_probs = model.predict(X_val, verbose=False)\n",
    "THRESH = 0.5\n",
    "y_pred = np.array(y_probs > THRESH, dtype=int).squeeze()\n",
    "\n",
    "print('Accuracy:', '{:.3f}'.format(accuracy_score(y_val, y_pred)))\n",
    "print('AUC:', '{:.3f}'.format(roc_auc_score(y_val, y_probs)))\n",
    "print('\\n', classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f526cb2d-4a32-484a-b592-9af2c746ebf1",
   "metadata": {},
   "source": [
    "### Might as well make a submission to Kaggle :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbc3b0d9-bc3d-4574-8fe3-6c8f54cbdbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (418, 25)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/titanic_test.csv')\n",
    "\n",
    "# impute age in the test data (with mean from training)\n",
    "missing_test = df_test['Age'].isna()\n",
    "df_test.loc[missing, 'Age'] = mean_age\n",
    "# add cabin types column\n",
    "df_test['cabin_types'] = df_test['Cabin'].apply(map_cabin_type)\n",
    "\n",
    "# vectorize\n",
    "X_test = vectorize_data(df_test, scaler, onehot_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f124be0-5c07-4e4d-a951-c2e5ded5049d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 485us/step\n"
     ]
    }
   ],
   "source": [
    "submission_probs = model.predict(X_test)\n",
    "submission_preds = np.array(submission_probs > THRESH, dtype=int).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a43beae-5d7f-45c3-b1b9-3033ae1a18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame.from_dict({'PassengerId': df_test['PassengerId'], 'Survived': submission_preds})\n",
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238c633-4c06-49f7-9c39-39704a80dcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-book",
   "language": "python",
   "name": "dl-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
